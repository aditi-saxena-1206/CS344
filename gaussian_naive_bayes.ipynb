{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOYTrcMfjf53iS/4ukEV/QR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditi-saxena-1206/CS344/blob/main/gaussian_naive_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgFTNz8_6zoX"
      },
      "source": [
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6awg_2-u7ByX"
      },
      "source": [
        "def load_data():\n",
        "  iris = datasets.load_iris()\n",
        "  #print(iris)\n",
        "  return iris"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3VRyJxeMTo7"
      },
      "source": [
        "def describe_data(X,Y,features,classes):\n",
        "  print(\"Total number of observation: \", X.shape[0])\n",
        "  print(\"Total number of labels: \", X.shape[1])\n",
        "  print(\"Features: \", features)\n",
        "  print(\"Labels: \",classes)\n"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmNAMspzNu5n"
      },
      "source": [
        "def split_data(X,Y,n):\n",
        "  \n",
        "  #Here, since we know that the data is sorted class-wise, so we simply take first 70% samples of each class\n",
        "  \n",
        "  class_len = int(X.shape[0]/n)\n",
        "  train_len = int(class_len * 70/100)\n",
        "  train_row_list = []\n",
        "  test_row_list = []\n",
        "\n",
        "  for i in range(class_len):\n",
        "    for j in range(n):\n",
        "      if (i<35):\n",
        "        train_row_list.append(j*class_len + i)\n",
        "      else:\n",
        "        test_row_list.append(j*class_len + i)\n",
        "  #print(train_row_list)\n",
        "  #print(test_row_list)\n",
        "  X_train = X[train_row_list,:]\n",
        "  X_test = X[test_row_list,:]\n",
        "  Y_train = Y[train_row_list]\n",
        "  Y_test = Y[test_row_list]\n",
        "\n",
        "  return [X_train,X_test,Y_train,Y_test]\n"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBP7qPAobXvV"
      },
      "source": [
        "def prior_prob(Y_train,n):\n",
        "  size = Y_train.shape[0]\n",
        "  prob = np.zeros(n)\n",
        "  for i in range(n):\n",
        "    prob[i] = np.sum(Y_train == i)\n",
        "  prob = prob/size\n",
        "  #print(prob)\n",
        "  return prob"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB-wL97mjHN7"
      },
      "source": [
        "def stat_summary(X_train,Y_train,classes,features):\n",
        "  #calculate mean and variance of each feature with respect to each class\n",
        "  summary = np.zeros((len(classes),2*len(features)))\n",
        "  for i in range(len(classes)):\n",
        "    for j in range(len(features)):\n",
        "      x_feature = X_train[:,j]\n",
        "      #print(x_feature)\n",
        "      temp_array = x_feature[i:len(X_train):3]\n",
        "      #print(temp_array)\n",
        "      temp_mean = temp_array.mean()\n",
        "      temp_std = temp_array.std()\n",
        "      summary[i][j*2] = temp_mean\n",
        "      summary[i][j*2+1] = temp_std\n",
        "      print(classes[i],\" : \",features[j],\" : \",temp_mean,\" : \",temp_std)\n",
        "  #print(X_train)\n",
        "  feature_name_list = []\n",
        "  for i in features:\n",
        "    feature_name_list.extend([i+\"(mean)\",i+\"(std. devation)\"])\n",
        "  #print(summary)\n",
        "  df = pd.DataFrame(summary,index = classes, columns = feature_name_list)\n",
        "  return df"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGZWzo1FFSFI"
      },
      "source": [
        "def normal_pdf(data_point,mean,std):\n",
        "  var = float(std)**2\n",
        "  denom = (2*math.pi*var) ** 0.5\n",
        "  num = math.exp(-(float(data_point) - float(mean))**2 / (2*var))\n",
        "  return (num/denom)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyc4M1arJcFb"
      },
      "source": [
        "def joint_probabilities(feature_list, prior, stat_df):\n",
        "  joint_prob = np.zeros(len(prior))\n",
        "  for i in range(len(prior)):\n",
        "    joint = 1\n",
        "    for j in range(len(feature_list)):\n",
        "      temp = normal_pdf(feature_list[j],stat_df.iloc[i,j*2], stat_df.iloc[i,j*2+1])\n",
        "      joint = joint*temp\n",
        "    joint_prob[i] = joint * prior[i]\n",
        "  return joint_prob"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CehqmvEYcG9t"
      },
      "source": [
        "def predict(posterior):\n",
        "  return np.argmax(posterior)\n"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmN0-Mmda-f1"
      },
      "source": [
        "def predict_test(X_test, prior, stat_df):\n",
        "  size = X_test.shape[0]\n",
        "  Y_pred = np.zeros(size, dtype=int)\n",
        "  for i in range(size):\n",
        "    features = X_test[i,:]\n",
        "    posterior = joint_probabilities(features,prior,stat_df)\n",
        "    #print(posterior)\n",
        "    Y_pred[i] = predict(posterior)\n",
        "\n",
        "  return Y_pred"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSm7BRFK70-J"
      },
      "source": [
        "def main():\n",
        "  print(\"Loading IRIS dataset from scikit-learn library...\")\n",
        "  dataset = load_data()\n",
        "  print(\"Dataset Loaded.\")\n",
        "\n",
        "  print(\"Description of data\")\n",
        "  X = dataset.data\n",
        "  Y = dataset.target\n",
        "  features = dataset.feature_names\n",
        "  classes = dataset.target_names\n",
        "  describe_data(X,Y,features, classes)\n",
        "\n",
        "  print(\"Splitting the data in the ratio train:test::70:30\")\n",
        "  splitted_data = split_data(X,Y,len(classes))\n",
        "  X_train = splitted_data[0]\n",
        "  X_test = splitted_data[1]\n",
        "  Y_train = splitted_data[2]\n",
        "  Y_test = splitted_data[3]\n",
        "  print(\"Data splitted.\")\n",
        "\n",
        "  print(\"Calculating Prior Probabilities for each class\")\n",
        "  prior_probability = prior_prob(Y_train,len(classes))\n",
        "\n",
        "  print(\"Calculating Summary Statistics\")\n",
        "  stat_df = stat_summary(X_train,Y_train,classes,features)\n",
        "  print(stat_df)\n",
        "\n",
        "  print(\"Predicting for test data...\")\n",
        "  Y_pred = predict_test(X_test,prior_probability, stat_df)\n",
        "  print(\"Prediction done\")\n",
        "\n",
        "  print(\"Checking Accuracy\")\n",
        "  print(\"Accuracy Score: \", accuracy_score(Y_test,Y_pred))\n",
        "\n"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5s7ThyA7tsB",
        "outputId": "2b5de9eb-9b7c-4e55-9a62-bec918430bcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if __name__=='__main__':\n",
        "  main()"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading IRIS dataset from scikit-learn library...\n",
            "Dataset Loaded.\n",
            "Description of data\n",
            "Total number of observation:  150\n",
            "Total number of labels:  4\n",
            "Features:  ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "Labels:  ['setosa' 'versicolor' 'virginica']\n",
            "Splitting the data in the ratio train:test::70:30\n",
            "Data splitted.\n",
            "Calculating Prior Probabilities for each class\n",
            "Calculating Summary Statistics\n",
            "setosa  :  sepal length (cm)  :  5.045714285714285  :  0.35724569947854995\n",
            "setosa  :  sepal width (cm)  :  3.4685714285714284  :  0.3693789603192507\n",
            "setosa  :  petal length (cm)  :  1.477142857142857  :  0.17085618728829774\n",
            "setosa  :  petal width (cm)  :  0.2428571428571428  :  0.09938586931957763\n",
            "versicolor  :  sepal length (cm)  :  6.00857142857143  :  0.5261023412506237\n",
            "versicolor  :  sepal width (cm)  :  2.7685714285714287  :  0.31511578694770825\n",
            "versicolor  :  petal length (cm)  :  4.314285714285714  :  0.466073481112065\n",
            "versicolor  :  petal width (cm)  :  1.342857142857143  :  0.21285234893930485\n",
            "virginica  :  sepal length (cm)  :  6.617142857142857  :  0.6859761404787504\n",
            "virginica  :  sepal width (cm)  :  2.937142857142857  :  0.34482767065445835\n",
            "virginica  :  petal length (cm)  :  5.6257142857142854  :  0.5977781992597289\n",
            "virginica  :  petal width (cm)  :  1.9771428571428573  :  0.26948173994403646\n",
            "            sepal length (cm)(mean)  ...  petal width (cm)(std. devation)\n",
            "setosa                     5.045714  ...                         0.099386\n",
            "versicolor                 6.008571  ...                         0.212852\n",
            "virginica                  6.617143  ...                         0.269482\n",
            "\n",
            "[3 rows x 8 columns]\n",
            "Predicting for test data...\n",
            "[7.01529597e-01 3.54763578e-18 4.63800140e-24]\n",
            "[3.60337310e-110 3.06973928e-002 3.82966173e-003]\n",
            "[1.72862779e-264 5.89247719e-011 2.23275382e-002]\n",
            "[8.90459567e-01 9.88135935e-18 2.38036779e-23]\n",
            "[4.97108777e-117 6.73115992e-002 1.23716816e-002]\n",
            "[1.42370215e-231 5.79630204e-009 2.35947705e-002]\n",
            "[1.04613663e+00 2.19291222e-19 6.23753296e-25]\n",
            "[4.06429301e-93 1.40452488e-01 1.87824746e-04]\n",
            "[3.57179356e-177 8.76992201e-004 1.48562943e-001]\n",
            "[1.75177132e-01 1.66165283e-18 1.80083515e-24]\n",
            "[9.17598129e-77 2.55653975e-01 1.18928732e-04]\n",
            "[1.73882341e-137 2.26888774e-002 4.51252744e-002]\n",
            "[3.30645131e+00 1.03140346e-16 1.27309927e-22]\n",
            "[6.58183462e-74 1.74682107e-01 2.77670786e-05]\n",
            "[1.64429416e-196 8.33396532e-006 1.52788128e-001]\n",
            "[1.84412954e+00 2.80077026e-17 6.00687557e-23]\n",
            "[2.16501035e-85 2.18891632e-01 6.96909095e-05]\n",
            "[9.22960438e-234 1.22010038e-008 5.73940129e-002]\n",
            "[3.89865517e-03 1.41145720e-17 5.67857175e-24]\n",
            "[2.27097322e-104 3.08680540e-001 3.79814521e-003]\n",
            "[6.99270594e-197 6.89928664e-007 6.03322158e-002]\n",
            "[3.00685026e-01 8.52373231e-19 1.36933463e-24]\n",
            "[8.35642191e-70 2.61589793e-01 2.61730866e-05]\n",
            "[4.62117692e-160 3.64044771e-003 5.61006152e-002]\n",
            "[4.51490114e-03 5.40576503e-13 1.09898874e-18]\n",
            "[1.20091407e-39 6.92540179e-04 1.80075159e-09]\n",
            "[4.79471628e-244 8.08237491e-009 7.02305798e-002]\n",
            "[3.33683879e-02 4.45535326e-14 1.12430819e-19]\n",
            "[2.48596837e-81 3.52646859e-01 1.44262788e-04]\n",
            "[1.67402397e-249 2.40260036e-010 1.91037162e-002]\n",
            "[1.01839329e+00 5.55696025e-16 3.57013161e-22]\n",
            "[1.61707325e-76 2.55711209e-01 8.11041330e-05]\n",
            "[2.76149008e-201 1.10451089e-006 8.19102725e-002]\n",
            "[1.75240518e+00 1.29282046e-17 4.28346974e-23]\n",
            "[4.12551868e-81 3.76800154e-01 2.23148951e-04]\n",
            "[5.22999359e-157 3.37511501e-003 4.94806861e-002]\n",
            "[1.09312212e+00 9.92404236e-18 1.11417802e-23]\n",
            "[8.94595369e-87 4.31434767e-01 6.66276797e-04]\n",
            "[4.51691277e-175 3.54729381e-004 1.66072309e-001]\n",
            "[2.17070771e+00 1.74526779e-17 4.95362312e-23]\n",
            "[4.73955448e-35 7.86422465e-04 2.78139076e-09]\n",
            "[6.27614559e-210 1.74010286e-007 3.39902834e-002]\n",
            "[2.77139108e+00 3.50481057e-17 4.01347556e-23]\n",
            "[2.48350041e-77 3.79209857e-01 1.37219101e-04]\n",
            "[1.11685888e-152 9.23272245e-003 6.90586346e-002]\n",
            "Prediction done\n",
            "Checking Accuracy\n",
            "Accuracy Score:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}